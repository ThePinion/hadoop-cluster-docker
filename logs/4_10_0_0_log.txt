

build docker hadoop image


start hadoop-master container...
start hadoop-slave1 container...
start hadoop-slave2 container...
start hadoop network...


Starting namenodes on [hadoop-master]
hadoop-master: Warning: Permanently added 'hadoop-master,172.18.0.2' (ECDSA) to the list of known hosts.

hadoop-master: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-hadoop-master.out
hadoop-slave1: Warning: Permanently added 'hadoop-slave1,172.18.0.3' (ECDSA) to the list of known hosts.

hadoop-slave2: Warning: Permanently added 'hadoop-slave2,172.18.0.4' (ECDSA) to the list of known hosts.

hadoop-slave2: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave2.out
hadoop-slave1: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave1.out
hadoop-slave3: ssh: Could not resolve hostname hadoop-slave3: Name or service not known

Starting secondary namenodes [0.0.0.0]
0.0.0.0: Warning: Permanently added '0.0.0.0' (ECDSA) to the list of known hosts.

0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-hadoop-master.out


starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-hadoop-master.out
hadoop-slave1: Warning: Permanently added 'hadoop-slave1,172.18.0.3' (ECDSA) to the list of known hosts.

hadoop-slave2: Warning: Permanently added 'hadoop-slave2,172.18.0.4' (ECDSA) to the list of known hosts.

hadoop-slave1: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave1.out
hadoop-slave2: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave2.out
hadoop-slave3: ssh: Could not resolve hostname hadoop-slave3: Name or service not known



start TFIDF...
24/01/21 19:19:06 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032
24/01/21 19:19:06 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/21 19:19:06 INFO input.FileInputFormat: Total input paths to process : 40
24/01/21 19:19:06 INFO mapreduce.JobSubmitter: number of splits:40
24/01/21 19:19:07 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705864734966_0001
24/01/21 19:19:07 INFO impl.YarnClientImpl: Submitted application application_1705864734966_0001
24/01/21 19:19:07 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705864734966_0001/
24/01/21 19:19:07 INFO mapreduce.Job: Running job: job_1705864734966_0001
24/01/21 19:19:12 INFO mapreduce.Job: Job job_1705864734966_0001 running in uber mode : false
24/01/21 19:19:12 INFO mapreduce.Job:  map 0% reduce 0%
24/01/21 19:19:27 INFO mapreduce.Job:  map 8% reduce 0%
24/01/21 19:19:28 INFO mapreduce.Job:  map 15% reduce 0%
24/01/21 19:19:31 INFO mapreduce.Job:  map 17% reduce 0%
24/01/21 19:19:33 INFO mapreduce.Job:  map 22% reduce 0%
24/01/21 19:19:34 INFO mapreduce.Job:  map 28% reduce 0%
24/01/21 19:19:35 INFO mapreduce.Job:  map 35% reduce 0%
24/01/21 19:19:40 INFO mapreduce.Job:  map 38% reduce 0%
24/01/21 19:19:44 INFO mapreduce.Job:  map 50% reduce 0%
24/01/21 19:19:53 INFO mapreduce.Job:  map 55% reduce 0%
24/01/21 19:19:54 INFO mapreduce.Job:  map 70% reduce 19%
24/01/21 19:19:56 INFO mapreduce.Job:  map 73% reduce 19%
24/01/21 19:19:57 INFO mapreduce.Job:  map 77% reduce 24%
24/01/21 19:19:58 INFO mapreduce.Job:  map 82% reduce 24%
24/01/21 19:20:00 INFO mapreduce.Job:  map 82% reduce 28%
24/01/21 19:20:02 INFO mapreduce.Job:  map 88% reduce 28%
24/01/21 19:20:03 INFO mapreduce.Job:  map 100% reduce 30%
24/01/21 19:20:05 INFO mapreduce.Job:  map 100% reduce 100%
24/01/21 19:20:05 INFO mapreduce.Job: Job job_1705864734966_0001 completed successfully
24/01/21 19:20:05 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=9429949
		FILE: Number of bytes written=23664893
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10176826
		HDFS: Number of bytes written=8824705
		HDFS: Number of read operations=123
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Killed map tasks=1
		Launched map tasks=40
		Launched reduce tasks=1
		Data-local map tasks=40
		Total time spent by all maps in occupied slots (ms)=571735
		Total time spent by all reduces in occupied slots (ms)=30736
		Total time spent by all map tasks (ms)=571735
		Total time spent by all reduce tasks (ms)=30736
		Total vcore-milliseconds taken by all map tasks=571735
		Total vcore-milliseconds taken by all reduce tasks=30736
		Total megabyte-milliseconds taken by all map tasks=585456640
		Total megabyte-milliseconds taken by all reduce tasks=31473664
	Map-Reduce Framework
		Map input records=212515
		Map output records=539117
		Map output bytes=37798874
		Map output materialized bytes=9430183
		Input split bytes=6062
		Combine input records=539117
		Combine output records=141487
		Reduce input groups=141487
		Reduce shuffle bytes=9430183
		Reduce input records=141487
		Reduce output records=141487
		Spilled Records=282974
		Shuffled Maps =40
		Failed Shuffles=0
		Merged Map outputs=40
		GC time elapsed (ms)=6132
		CPU time spent (ms)=39340
		Physical memory (bytes) snapshot=11258658816
		Virtual memory (bytes) snapshot=33952624640
		Total committed heap usage (bytes)=8246525952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10170764
	File Output Format Counters 
		Bytes Written=8824705
24/01/21 19:20:05 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032
24/01/21 19:20:05 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/21 19:20:05 INFO input.FileInputFormat: Total input paths to process : 1
24/01/21 19:20:05 INFO mapreduce.JobSubmitter: number of splits:1
24/01/21 19:20:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705864734966_0002
24/01/21 19:20:05 INFO impl.YarnClientImpl: Submitted application application_1705864734966_0002
24/01/21 19:20:05 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705864734966_0002/
24/01/21 19:20:05 INFO mapreduce.Job: Running job: job_1705864734966_0002
24/01/21 19:20:15 INFO mapreduce.Job: Job job_1705864734966_0002 running in uber mode : false
24/01/21 19:20:15 INFO mapreduce.Job:  map 0% reduce 0%
24/01/21 19:20:19 INFO mapreduce.Job:  map 100% reduce 0%
24/01/21 19:20:25 INFO mapreduce.Job:  map 100% reduce 100%
24/01/21 19:20:25 INFO mapreduce.Job: Job job_1705864734966_0002 completed successfully
24/01/21 19:20:25 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=9155421
		FILE: Number of bytes written=18544861
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=8824824
		HDFS: Number of bytes written=9644845
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2450
		Total time spent by all reduces in occupied slots (ms)=2817
		Total time spent by all map tasks (ms)=2450
		Total time spent by all reduce tasks (ms)=2817
		Total vcore-milliseconds taken by all map tasks=2450
		Total vcore-milliseconds taken by all reduce tasks=2817
		Total megabyte-milliseconds taken by all map tasks=2508800
		Total megabyte-milliseconds taken by all reduce tasks=2884608
	Map-Reduce Framework
		Map input records=141487
		Map output records=141487
		Map output bytes=8848573
		Map output materialized bytes=9155421
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=40
		Reduce shuffle bytes=9155421
		Reduce input records=141487
		Reduce output records=141487
		Spilled Records=282974
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=95
		CPU time spent (ms)=3890
		Physical memory (bytes) snapshot=496214016
		Virtual memory (bytes) snapshot=1700335616
		Total committed heap usage (bytes)=386400256
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	TFIDF$Counters
		DOCUMENTS=40
	File Input Format Counters 
		Bytes Read=8824705
	File Output Format Counters 
		Bytes Written=9644845
24/01/21 19:20:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.18.0.2:8032
24/01/21 19:20:25 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/21 19:20:25 INFO input.FileInputFormat: Total input paths to process : 1
24/01/21 19:20:25 INFO mapreduce.JobSubmitter: number of splits:1
24/01/21 19:20:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705864734966_0003
24/01/21 19:20:26 INFO impl.YarnClientImpl: Submitted application application_1705864734966_0003
24/01/21 19:20:26 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705864734966_0003/
24/01/21 19:20:26 INFO mapreduce.Job: Running job: job_1705864734966_0003
24/01/21 19:20:35 INFO mapreduce.Job: Job job_1705864734966_0003 running in uber mode : false
24/01/21 19:20:35 INFO mapreduce.Job:  map 0% reduce 0%
24/01/21 19:20:40 INFO mapreduce.Job:  map 100% reduce 0%
24/01/21 19:20:46 INFO mapreduce.Job:  map 100% reduce 100%
24/01/21 19:20:46 INFO mapreduce.Job: Job job_1705864734966_0003 completed successfully
24/01/21 19:20:46 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=9975561
		FILE: Number of bytes written=20185459
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=9644968
		HDFS: Number of bytes written=12525377
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=2358
		Total time spent by all reduces in occupied slots (ms)=3364
		Total time spent by all map tasks (ms)=2358
		Total time spent by all reduce tasks (ms)=3364
		Total vcore-milliseconds taken by all map tasks=2358
		Total vcore-milliseconds taken by all reduce tasks=3364
		Total megabyte-milliseconds taken by all map tasks=2414592
		Total megabyte-milliseconds taken by all reduce tasks=3444736
	Map-Reduce Framework
		Map input records=141487
		Map output records=141487
		Map output bytes=9668713
		Map output materialized bytes=9975561
		Input split bytes=123
		Combine input records=0
		Combine output records=0
		Reduce input groups=40829
		Reduce shuffle bytes=9975561
		Reduce input records=141487
		Reduce output records=141487
		Spilled Records=282974
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=126
		CPU time spent (ms)=4790
		Physical memory (bytes) snapshot=481234944
		Virtual memory (bytes) snapshot=1690095616
		Total committed heap usage (bytes)=396361728
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=9644845
	File Output Format Counters 
		Bytes Written=12525377
--TIME1:59950 ms--
--TIME2:20398 ms--
--TIME3:20390 ms--
