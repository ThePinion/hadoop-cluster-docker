

build docker hadoop image


start hadoop-master container...
start hadoop-slave1 container...
start hadoop-slave2 container...
start hadoop-slave3 container...
start hadoop-slave4 container...
start hadoop-slave5 container...
start hadoop network...


Starting namenodes on [hadoop-master]
hadoop-master: Warning: Permanently added 'hadoop-master,172.20.0.2' (ECDSA) to the list of known hosts.

hadoop-master: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-hadoop-master.out
hadoop-slave5: Warning: Permanently added 'hadoop-slave5,172.20.0.7' (ECDSA) to the list of known hosts.

hadoop-slave3: Warning: Permanently added 'hadoop-slave3,172.20.0.5' (ECDSA) to the list of known hosts.

hadoop-slave1: Warning: Permanently added 'hadoop-slave1,172.20.0.3' (ECDSA) to the list of known hosts.

hadoop-slave4: Warning: Permanently added 'hadoop-slave4,172.20.0.6' (ECDSA) to the list of known hosts.

hadoop-slave2: Warning: Permanently added 'hadoop-slave2,172.20.0.4' (ECDSA) to the list of known hosts.

hadoop-slave3: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave3.out
hadoop-slave4: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave4.out
hadoop-slave1: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave1.out
hadoop-slave5: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave5.out
hadoop-slave2: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave2.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: Warning: Permanently added '0.0.0.0' (ECDSA) to the list of known hosts.

0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-hadoop-master.out


starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-hadoop-master.out
hadoop-slave4: Warning: Permanently added 'hadoop-slave4,172.20.0.6' (ECDSA) to the list of known hosts.

hadoop-slave3: Warning: Permanently added 'hadoop-slave3,172.20.0.5' (ECDSA) to the list of known hosts.

hadoop-slave1: Warning: Permanently added 'hadoop-slave1,172.20.0.3' (ECDSA) to the list of known hosts.

hadoop-slave5: Warning: Permanently added 'hadoop-slave5,172.20.0.7' (ECDSA) to the list of known hosts.

hadoop-slave2: Warning: Permanently added 'hadoop-slave2,172.20.0.4' (ECDSA) to the list of known hosts.

hadoop-slave4: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave4.out
hadoop-slave5: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave5.out
hadoop-slave3: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave3.out
hadoop-slave1: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave1.out
hadoop-slave2: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave2.out


start TFIDF...
24/01/22 01:43:01 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/01/22 01:43:01 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/22 01:43:02 INFO input.FileInputFormat: Total input paths to process : 74
24/01/22 01:43:02 INFO mapreduce.JobSubmitter: number of splits:74
24/01/22 01:43:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705887762600_0001
24/01/22 01:43:02 INFO impl.YarnClientImpl: Submitted application application_1705887762600_0001
24/01/22 01:43:02 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705887762600_0001/
24/01/22 01:43:02 INFO mapreduce.Job: Running job: job_1705887762600_0001
24/01/22 01:43:10 INFO mapreduce.Job: Job job_1705887762600_0001 running in uber mode : false
24/01/22 01:43:10 INFO mapreduce.Job:  map 0% reduce 0%
24/01/22 01:43:53 INFO mapreduce.Job:  map 2% reduce 0%
24/01/22 01:43:56 INFO mapreduce.Job:  map 3% reduce 0%
24/01/22 01:43:57 INFO mapreduce.Job:  map 5% reduce 0%
24/01/22 01:44:00 INFO mapreduce.Job:  map 6% reduce 0%
24/01/22 01:44:01 INFO mapreduce.Job:  map 7% reduce 0%
24/01/22 01:44:02 INFO mapreduce.Job:  map 8% reduce 0%
24/01/22 01:44:11 INFO mapreduce.Job:  map 12% reduce 0%
24/01/22 01:44:12 INFO mapreduce.Job:  map 14% reduce 0%
24/01/22 01:44:13 INFO mapreduce.Job:  map 20% reduce 0%
24/01/22 01:44:14 INFO mapreduce.Job:  map 26% reduce 0%
24/01/22 01:44:15 INFO mapreduce.Job:  map 28% reduce 0%
24/01/22 01:44:16 INFO mapreduce.Job:  map 34% reduce 0%
24/01/22 01:44:17 INFO mapreduce.Job:  map 37% reduce 0%
24/01/22 01:44:18 INFO mapreduce.Job:  map 41% reduce 0%
24/01/22 01:44:19 INFO mapreduce.Job:  map 44% reduce 0%
24/01/22 01:44:20 INFO mapreduce.Job:  map 46% reduce 0%
24/01/22 01:44:21 INFO mapreduce.Job:  map 49% reduce 0%
24/01/22 01:44:22 INFO mapreduce.Job:  map 51% reduce 0%
24/01/22 01:44:45 INFO mapreduce.Job:  map 52% reduce 0%
24/01/22 01:44:47 INFO mapreduce.Job:  map 54% reduce 0%
24/01/22 01:44:50 INFO mapreduce.Job:  map 55% reduce 0%
24/01/22 01:44:51 INFO mapreduce.Job:  map 58% reduce 18%
24/01/22 01:44:54 INFO mapreduce.Job:  map 58% reduce 19%
24/01/22 01:45:07 INFO mapreduce.Job:  map 61% reduce 19%
24/01/22 01:45:08 INFO mapreduce.Job:  map 65% reduce 19%
24/01/22 01:45:09 INFO mapreduce.Job:  map 68% reduce 20%
24/01/22 01:45:10 INFO mapreduce.Job:  map 72% reduce 20%
24/01/22 01:45:11 INFO mapreduce.Job:  map 74% reduce 20%
24/01/22 01:45:12 INFO mapreduce.Job:  map 82% reduce 23%
24/01/22 01:45:13 INFO mapreduce.Job:  map 91% reduce 23%
24/01/22 01:45:14 INFO mapreduce.Job:  map 100% reduce 23%
24/01/22 01:45:15 INFO mapreduce.Job:  map 100% reduce 31%
24/01/22 01:45:16 INFO mapreduce.Job:  map 100% reduce 100%
24/01/22 01:45:16 INFO mapreduce.Job: Job job_1705887762600_0001 completed successfully
24/01/22 01:45:17 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=12962200
		FILE: Number of bytes written=34714093
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=20631877
		HDFS: Number of bytes written=11908066
		HDFS: Number of read operations=225
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Killed map tasks=3
		Launched map tasks=76
		Launched reduce tasks=1
		Data-local map tasks=73
		Rack-local map tasks=3
		Total time spent by all maps in occupied slots (ms)=4278589
		Total time spent by all reduces in occupied slots (ms)=69762
		Total time spent by all map tasks (ms)=4278589
		Total time spent by all reduce tasks (ms)=69762
		Total vcore-milliseconds taken by all map tasks=4278589
		Total vcore-milliseconds taken by all reduce tasks=69762
		Total megabyte-milliseconds taken by all map tasks=4381275136
		Total megabyte-milliseconds taken by all reduce tasks=71436288
	Map-Reduce Framework
		Map input records=421241
		Map output records=978122
		Map output bytes=43905317
		Map output materialized bytes=12962638
		Input split bytes=10484
		Combine input records=978122
		Combine output records=267667
		Reduce input groups=267667
		Reduce shuffle bytes=12962638
		Reduce input records=267667
		Reduce output records=267667
		Spilled Records=535334
		Shuffled Maps =74
		Failed Shuffles=0
		Merged Map outputs=74
		GC time elapsed (ms)=32062
		CPU time spent (ms)=96440
		Physical memory (bytes) snapshot=20629520384
		Virtual memory (bytes) snapshot=62116876288
		Total committed heap usage (bytes)=15084290048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=20621393
	File Output Format Counters 
		Bytes Written=11908066
24/01/22 01:45:17 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/01/22 01:45:17 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/22 01:45:17 INFO input.FileInputFormat: Total input paths to process : 1
24/01/22 01:45:17 INFO mapreduce.JobSubmitter: number of splits:1
24/01/22 01:45:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705887762600_0002
24/01/22 01:45:17 INFO impl.YarnClientImpl: Submitted application application_1705887762600_0002
24/01/22 01:45:17 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705887762600_0002/
24/01/22 01:45:17 INFO mapreduce.Job: Running job: job_1705887762600_0002
24/01/22 01:45:22 INFO mapreduce.Job: Job job_1705887762600_0002 running in uber mode : false
24/01/22 01:45:22 INFO mapreduce.Job:  map 0% reduce 0%
24/01/22 01:45:28 INFO mapreduce.Job:  map 100% reduce 0%
24/01/22 01:45:34 INFO mapreduce.Job:  map 100% reduce 100%
24/01/22 01:45:34 INFO mapreduce.Job: Job job_1705887762600_0002 completed successfully
24/01/22 01:45:34 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=12443406
		FILE: Number of bytes written=25120831
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=11908185
		HDFS: Number of bytes written=13456788
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3301
		Total time spent by all reduces in occupied slots (ms)=3719
		Total time spent by all map tasks (ms)=3301
		Total time spent by all reduce tasks (ms)=3719
		Total vcore-milliseconds taken by all map tasks=3301
		Total vcore-milliseconds taken by all reduce tasks=3719
		Total megabyte-milliseconds taken by all map tasks=3380224
		Total megabyte-milliseconds taken by all reduce tasks=3808256
	Map-Reduce Framework
		Map input records=267667
		Map output records=267667
		Map output bytes=11908066
		Map output materialized bytes=12443406
		Input split bytes=119
		Combine input records=0
		Combine output records=0
		Reduce input groups=74
		Reduce shuffle bytes=12443406
		Reduce input records=267667
		Reduce output records=267667
		Spilled Records=535334
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=121
		CPU time spent (ms)=5290
		Physical memory (bytes) snapshot=491827200
		Virtual memory (bytes) snapshot=1699278848
		Total committed heap usage (bytes)=395837440
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	TFIDF$Counters
		DOCUMENTS=74
	File Input Format Counters 
		Bytes Read=11908066
	File Output Format Counters 
		Bytes Written=13456788
24/01/22 01:45:34 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/01/22 01:45:34 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/22 01:45:34 INFO input.FileInputFormat: Total input paths to process : 1
24/01/22 01:45:34 INFO mapreduce.JobSubmitter: number of splits:1
24/01/22 01:45:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705887762600_0003
24/01/22 01:45:34 INFO impl.YarnClientImpl: Submitted application application_1705887762600_0003
24/01/22 01:45:34 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705887762600_0003/
24/01/22 01:45:34 INFO mapreduce.Job: Running job: job_1705887762600_0003
24/01/22 01:45:40 INFO mapreduce.Job: Job job_1705887762600_0003 running in uber mode : false
24/01/22 01:45:40 INFO mapreduce.Job:  map 0% reduce 0%
24/01/22 01:45:46 INFO mapreduce.Job:  map 100% reduce 0%
24/01/22 01:45:52 INFO mapreduce.Job:  map 100% reduce 100%
24/01/22 01:45:53 INFO mapreduce.Job: Job job_1705887762600_0003 completed successfully
24/01/22 01:45:53 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=13992128
		FILE: Number of bytes written=28218593
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=13456911
		HDFS: Number of bytes written=18958340
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3558
		Total time spent by all reduces in occupied slots (ms)=4229
		Total time spent by all map tasks (ms)=3558
		Total time spent by all reduce tasks (ms)=4229
		Total vcore-milliseconds taken by all map tasks=3558
		Total vcore-milliseconds taken by all reduce tasks=4229
		Total megabyte-milliseconds taken by all map tasks=3643392
		Total megabyte-milliseconds taken by all reduce tasks=4330496
	Map-Reduce Framework
		Map input records=267667
		Map output records=267667
		Map output bytes=13456788
		Map output materialized bytes=13992128
		Input split bytes=123
		Combine input records=0
		Combine output records=0
		Reduce input groups=45427
		Reduce shuffle bytes=13992128
		Reduce input records=267667
		Reduce output records=267667
		Spilled Records=535334
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=143
		CPU time spent (ms)=6060
		Physical memory (bytes) snapshot=502743040
		Virtual memory (bytes) snapshot=1679126528
		Total committed heap usage (bytes)=402128896
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=13456788
	File Output Format Counters 
		Bytes Written=18958340
--TIME1:137004 ms--
--TIME2:17630 ms--
--TIME3:18596 ms--
