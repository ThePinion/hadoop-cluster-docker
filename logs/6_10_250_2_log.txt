

build docker hadoop image


start hadoop-master container...
start hadoop-slave1 container...
start hadoop-slave2 container...
start hadoop-slave3 container...
start hadoop-slave4 container...
start hadoop-slave5 container...
start hadoop network...


Starting namenodes on [hadoop-master]
hadoop-master: Warning: Permanently added 'hadoop-master,172.20.0.2' (ECDSA) to the list of known hosts.

hadoop-master: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-hadoop-master.out
hadoop-slave3: Warning: Permanently added 'hadoop-slave3,172.20.0.5' (ECDSA) to the list of known hosts.

hadoop-slave2: Warning: Permanently added 'hadoop-slave2,172.20.0.4' (ECDSA) to the list of known hosts.

hadoop-slave4: Warning: Permanently added 'hadoop-slave4,172.20.0.6' (ECDSA) to the list of known hosts.

hadoop-slave1: Warning: Permanently added 'hadoop-slave1,172.20.0.3' (ECDSA) to the list of known hosts.

hadoop-slave5: Warning: Permanently added 'hadoop-slave5,172.20.0.7' (ECDSA) to the list of known hosts.

hadoop-slave3: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave3.out
hadoop-slave2: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave2.out
hadoop-slave1: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave1.out
hadoop-slave4: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave4.out
hadoop-slave5: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-hadoop-slave5.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: Warning: Permanently added '0.0.0.0' (ECDSA) to the list of known hosts.

0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-hadoop-master.out


starting yarn daemons
starting resourcemanager, logging to /usr/local/hadoop/logs/yarn--resourcemanager-hadoop-master.out
hadoop-slave2: Warning: Permanently added 'hadoop-slave2,172.20.0.4' (ECDSA) to the list of known hosts.

hadoop-slave5: Warning: Permanently added 'hadoop-slave5,172.20.0.7' (ECDSA) to the list of known hosts.

hadoop-slave4: Warning: Permanently added 'hadoop-slave4,172.20.0.6' (ECDSA) to the list of known hosts.

hadoop-slave3: Warning: Permanently added 'hadoop-slave3,172.20.0.5' (ECDSA) to the list of known hosts.

hadoop-slave1: Warning: Permanently added 'hadoop-slave1,172.20.0.3' (ECDSA) to the list of known hosts.

hadoop-slave2: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave2.out
hadoop-slave5: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave5.out
hadoop-slave4: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave4.out
hadoop-slave1: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave1.out
hadoop-slave3: starting nodemanager, logging to /usr/local/hadoop/logs/yarn-root-nodemanager-hadoop-slave3.out


start TFIDF...
24/01/22 01:29:25 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/01/22 01:29:26 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/22 01:29:26 INFO input.FileInputFormat: Total input paths to process : 40
24/01/22 01:29:26 INFO mapreduce.JobSubmitter: number of splits:40
24/01/22 01:29:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705886947573_0001
24/01/22 01:29:27 INFO impl.YarnClientImpl: Submitted application application_1705886947573_0001
24/01/22 01:29:27 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705886947573_0001/
24/01/22 01:29:27 INFO mapreduce.Job: Running job: job_1705886947573_0001
24/01/22 01:29:34 INFO mapreduce.Job: Job job_1705886947573_0001 running in uber mode : false
24/01/22 01:29:34 INFO mapreduce.Job:  map 0% reduce 0%
24/01/22 01:30:16 INFO mapreduce.Job:  map 1% reduce 0%
24/01/22 01:30:17 INFO mapreduce.Job:  map 3% reduce 0%
24/01/22 01:30:18 INFO mapreduce.Job:  map 4% reduce 0%
24/01/22 01:30:20 INFO mapreduce.Job:  map 9% reduce 0%
24/01/22 01:30:21 INFO mapreduce.Job:  map 10% reduce 0%
24/01/22 01:30:23 INFO mapreduce.Job:  map 12% reduce 0%
24/01/22 01:30:24 INFO mapreduce.Job:  map 13% reduce 0%
24/01/22 01:30:25 INFO mapreduce.Job:  map 14% reduce 0%
24/01/22 01:30:26 INFO mapreduce.Job:  map 15% reduce 0%
24/01/22 01:30:32 INFO mapreduce.Job:  map 17% reduce 0%
24/01/22 01:30:33 INFO mapreduce.Job:  map 18% reduce 0%
24/01/22 01:30:34 INFO mapreduce.Job:  map 19% reduce 0%
24/01/22 01:30:35 INFO mapreduce.Job:  map 25% reduce 0%
24/01/22 01:30:36 INFO mapreduce.Job:  map 35% reduce 0%
24/01/22 01:30:37 INFO mapreduce.Job:  map 45% reduce 0%
24/01/22 01:30:38 INFO mapreduce.Job:  map 60% reduce 0%
24/01/22 01:30:39 INFO mapreduce.Job:  map 73% reduce 0%
24/01/22 01:30:40 INFO mapreduce.Job:  map 81% reduce 0%
24/01/22 01:30:41 INFO mapreduce.Job:  map 87% reduce 0%
24/01/22 01:30:42 INFO mapreduce.Job:  map 94% reduce 0%
24/01/22 01:30:43 INFO mapreduce.Job:  map 95% reduce 0%
24/01/22 01:30:44 INFO mapreduce.Job:  map 98% reduce 0%
24/01/22 01:30:45 INFO mapreduce.Job:  map 100% reduce 0%
24/01/22 01:30:46 INFO mapreduce.Job:  map 100% reduce 100%
24/01/22 01:30:47 INFO mapreduce.Job: Job job_1705886947573_0001 completed successfully
24/01/22 01:30:47 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=6612062
		FILE: Number of bytes written=18147318
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=10213848
		HDFS: Number of bytes written=6072302
		HDFS: Number of read operations=126
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Killed map tasks=1
		Launched map tasks=40
		Launched reduce tasks=2
		Data-local map tasks=34
		Rack-local map tasks=6
		Total time spent by all maps in occupied slots (ms)=2343140
		Total time spent by all reduces in occupied slots (ms)=39278
		Total time spent by all map tasks (ms)=2343140
		Total time spent by all reduce tasks (ms)=39278
		Total vcore-milliseconds taken by all map tasks=2343140
		Total vcore-milliseconds taken by all reduce tasks=39278
		Total megabyte-milliseconds taken by all map tasks=2399375360
		Total megabyte-milliseconds taken by all reduce tasks=40220672
	Map-Reduce Framework
		Map input records=211471
		Map output records=488769
		Map output bytes=21915732
		Map output materialized bytes=6612530
		Input split bytes=5668
		Combine input records=488769
		Combine output records=136975
		Reduce input groups=136975
		Reduce shuffle bytes=6612530
		Reduce input records=136975
		Reduce output records=136975
		Spilled Records=273950
		Shuffled Maps =80
		Failed Shuffles=0
		Merged Map outputs=80
		GC time elapsed (ms)=18780
		CPU time spent (ms)=53210
		Physical memory (bytes) snapshot=11399110656
		Virtual memory (bytes) snapshot=34733346816
		Total committed heap usage (bytes)=8452571136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10208180
	File Output Format Counters 
		Bytes Written=6072302
24/01/22 01:30:48 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/01/22 01:30:48 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/22 01:30:48 INFO input.FileInputFormat: Total input paths to process : 2
24/01/22 01:30:48 INFO mapreduce.JobSubmitter: number of splits:2
24/01/22 01:30:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705886947573_0002
24/01/22 01:30:48 INFO impl.YarnClientImpl: Submitted application application_1705886947573_0002
24/01/22 01:30:48 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705886947573_0002/
24/01/22 01:30:48 INFO mapreduce.Job: Running job: job_1705886947573_0002
24/01/22 01:30:53 INFO mapreduce.Job: Job job_1705886947573_0002 running in uber mode : false
24/01/22 01:30:53 INFO mapreduce.Job:  map 0% reduce 0%
24/01/22 01:30:59 INFO mapreduce.Job:  map 100% reduce 0%
24/01/22 01:31:05 INFO mapreduce.Job:  map 100% reduce 50%
24/01/22 01:31:06 INFO mapreduce.Job:  map 100% reduce 100%
24/01/22 01:31:06 INFO mapreduce.Job: Job job_1705886947573_0002 completed successfully
24/01/22 01:31:06 INFO mapreduce.Job: Counters: 51
	File System Counters
		FILE: Number of bytes read=6346264
		FILE: Number of bytes written=13160614
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6072540
		HDFS: Number of bytes written=6869318
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=2
		Data-local map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=7104
		Total time spent by all reduces in occupied slots (ms)=8301
		Total time spent by all map tasks (ms)=7104
		Total time spent by all reduce tasks (ms)=8301
		Total vcore-milliseconds taken by all map tasks=7104
		Total vcore-milliseconds taken by all reduce tasks=8301
		Total megabyte-milliseconds taken by all map tasks=7274496
		Total megabyte-milliseconds taken by all reduce tasks=8500224
	Map-Reduce Framework
		Map input records=136975
		Map output records=136975
		Map output bytes=6072302
		Map output materialized bytes=6346276
		Input split bytes=238
		Combine input records=0
		Combine output records=0
		Reduce input groups=40
		Reduce shuffle bytes=6346276
		Reduce input records=136975
		Reduce output records=136975
		Spilled Records=273950
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=238
		CPU time spent (ms)=7120
		Physical memory (bytes) snapshot=952020992
		Virtual memory (bytes) snapshot=3349286912
		Total committed heap usage (bytes)=786432000
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	TFIDF$Counters
		DOCUMENTS=40
	File Input Format Counters 
		Bytes Read=6072302
	File Output Format Counters 
		Bytes Written=6869318
24/01/22 01:31:06 INFO client.RMProxy: Connecting to ResourceManager at hadoop-master/172.20.0.2:8032
24/01/22 01:31:06 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
24/01/22 01:31:06 INFO input.FileInputFormat: Total input paths to process : 2
24/01/22 01:31:06 INFO mapreduce.JobSubmitter: number of splits:2
24/01/22 01:31:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1705886947573_0003
24/01/22 01:31:06 INFO impl.YarnClientImpl: Submitted application application_1705886947573_0003
24/01/22 01:31:06 INFO mapreduce.Job: The url to track the job: http://hadoop-master:8088/proxy/application_1705886947573_0003/
24/01/22 01:31:06 INFO mapreduce.Job: Running job: job_1705886947573_0003
24/01/22 01:31:12 INFO mapreduce.Job: Job job_1705886947573_0003 running in uber mode : false
24/01/22 01:31:12 INFO mapreduce.Job:  map 0% reduce 0%
24/01/22 01:31:18 INFO mapreduce.Job:  map 100% reduce 0%
24/01/22 01:31:24 INFO mapreduce.Job:  map 100% reduce 50%
24/01/22 01:31:25 INFO mapreduce.Job:  map 100% reduce 100%
24/01/22 01:31:25 INFO mapreduce.Job: Job job_1705886947573_0003 completed successfully
24/01/22 01:31:25 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=7143280
		FILE: Number of bytes written=14755282
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=6869564
		HDFS: Number of bytes written=9666754
		HDFS: Number of read operations=12
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=2
		Data-local map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=6634
		Total time spent by all reduces in occupied slots (ms)=8369
		Total time spent by all map tasks (ms)=6634
		Total time spent by all reduce tasks (ms)=8369
		Total vcore-milliseconds taken by all map tasks=6634
		Total vcore-milliseconds taken by all reduce tasks=8369
		Total megabyte-milliseconds taken by all map tasks=6793216
		Total megabyte-milliseconds taken by all reduce tasks=8569856
	Map-Reduce Framework
		Map input records=136975
		Map output records=136975
		Map output bytes=6869318
		Map output materialized bytes=7143292
		Input split bytes=246
		Combine input records=0
		Combine output records=0
		Reduce input groups=30591
		Reduce shuffle bytes=7143292
		Reduce input records=136975
		Reduce output records=136975
		Spilled Records=273950
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=291
		CPU time spent (ms)=8740
		Physical memory (bytes) snapshot=968384512
		Virtual memory (bytes) snapshot=3374481408
		Total committed heap usage (bytes)=797442048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6869318
	File Output Format Counters 
		Bytes Written=9666754
--TIME1:83190 ms--
--TIME2:18654 ms--
--TIME3:18576 ms--
